From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Tavi <tavi@divested.dev>
Date: Sat, 22 Mar 2025 02:54:10 -0400
Subject: [PATCH] perform size checks on memcpy/memmove/memset

- underlying functions were copied from musl, licensed MIT

Signed-off-by: Tavi <tavi@divested.dev>
---
 Android.bp                        |   1 +
 CREDITS                           |  24 ++++
 Makefile                          |  45 +++++++-
 README.md                         |   3 +
 config/default.mk                 |   1 +
 config/light.mk                   |   1 +
 h_malloc.c                        | 156 ++++++++++++++++++++++++-
 include/h_malloc.h                |  43 +++++++
 test/.gitignore                   |  11 ++
 test/Makefile                     |  13 ++-
 test/memcpy_buffer_overflow.c     |  15 +++
 test/memcpy_read_overflow.c       |  15 +++
 test/memcpy_valid_mismatched.c    |  15 +++
 test/memcpy_valid_same.c          |  15 +++
 test/memmove_buffer_overflow.c    |  15 +++
 test/memmove_read_overflow.c      |  15 +++
 test/memmove_valid_mismatched.c   |  15 +++
 test/memmove_valid_same.c         |  15 +++
 test/memset_buffer_overflow.c     |  13 +++
 test/memset_valid_mismatched.c    |  13 +++
 test/memset_valid_same.c          |  13 +++
 test/test_smc.py                  |  65 +++++++++++
 third_party/musl/aarch64/memcpy.S | 186 ++++++++++++++++++++++++++++++
 third_party/musl/aarch64/memset.S | 115 ++++++++++++++++++
 third_party/musl/x86_64/memcpy.S  |  25 ++++
 third_party/musl/x86_64/memmove.S |  16 +++
 third_party/musl/x86_64/memset.S  |  72 ++++++++++++
 27 files changed, 928 insertions(+), 8 deletions(-)
 create mode 100644 test/memcpy_buffer_overflow.c
 create mode 100644 test/memcpy_read_overflow.c
 create mode 100644 test/memcpy_valid_mismatched.c
 create mode 100644 test/memcpy_valid_same.c
 create mode 100644 test/memmove_buffer_overflow.c
 create mode 100644 test/memmove_read_overflow.c
 create mode 100644 test/memmove_valid_mismatched.c
 create mode 100644 test/memmove_valid_same.c
 create mode 100644 test/memset_buffer_overflow.c
 create mode 100644 test/memset_valid_mismatched.c
 create mode 100644 test/memset_valid_same.c
 create mode 100644 third_party/musl/aarch64/memcpy.S
 create mode 100644 third_party/musl/aarch64/memset.S
 create mode 100644 third_party/musl/x86_64/memcpy.S
 create mode 100644 third_party/musl/x86_64/memmove.S
 create mode 100644 third_party/musl/x86_64/memset.S

diff --git a/Android.bp b/Android.bp
index f6a7a9c..a2bab52 100644
--- a/Android.bp
+++ b/Android.bp
@@ -28,6 +28,7 @@ common_cflags = [
     "-DN_ARENA=1",
     "-DCONFIG_STATS=true",
     "-DCONFIG_SELF_INIT=false",
+    "-DCONFIG_BLOCK_OPS_CHECK_SIZE=false",
 ]
 
 cc_defaults {
diff --git a/CREDITS b/CREDITS
index 31b6875..bf62056 100644
--- a/CREDITS
+++ b/CREDITS
@@ -23,6 +23,30 @@ h_malloc.c open-addressed hash table (regions_grow, regions_insert, regions_find
     ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
     OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 
+*_musl functions and third_party/musl extracted from musl and macros removed:
+    Copyright Â© 2005-2020 Rich Felker, et al.
+
+    Permission is hereby granted, free of charge, to any person obtaining
+    a copy of this software and associated documentation files (the
+    "Software"), to deal in the Software without restriction, including
+    without limitation the rights to use, copy, modify, merge, publish,
+    distribute, sublicense, and/or sell copies of the Software, and to
+    permit persons to whom the Software is furnished to do so, subject to
+    the following conditions:
+
+    The above copyright notice and this permission notice shall be
+    included in all copies or substantial portions of the Software.
+
+    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+    EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+    MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
+    IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
+    CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+    TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+    SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+
+    Contributor list: https://git.musl-libc.org/cgit/musl/tree/COPYRIGHT
+
 libdivide:
 
     Copyright (C) 2010 - 2019 ridiculous_fish, <libdivide@ridiculousfish.com>
diff --git a/Makefile b/Makefile
index f33f88e..b0bea1b 100644
--- a/Makefile
+++ b/Makefile
@@ -42,6 +42,37 @@ LDFLAGS := $(LDFLAGS) -Wl,-O1,--as-needed,-z,defs,-z,relro,-z,now,-z,nodlopen,-z
 SOURCES := chacha.c h_malloc.c memory.c pages.c random.c util.c
 OBJECTS := $(SOURCES:.c=.o)
 
+ASSEMBLYARCH := x86_64
+ifeq ($(CONFIG_BLOCK_OPS_CHECK_SIZE),true)
+	ifneq (,$(findstring aarch64,$(CFLAGS)))
+		ASSEMBLYARCH := aarch64
+	endif
+	ifneq (,$(findstring x86_64,$(CFLAGS)))
+		ASSEMBLYARCH := x86_64
+	endif
+	ifneq (,$(findstring march=native,$(CFLAGS)))
+		MACHINE := $(shell uname -m)
+		ifneq (,$(findstring aarch64,$(MACHINE)))
+			ASSEMBLYARCH := aarch64
+		endif
+		ifneq (,$(findstring x86_64,$(MACHINE)))
+			ASSEMBLYARCH := x86_64
+		endif
+	endif
+
+	ifneq (,$(findstring unknown,$(ASSEMBLYARCH)))
+		ASSEMBLYARCH := 0
+	endif
+	ifneq (,$(findstring aarch64,$(ASSEMBLYARCH)))
+		OBJECTS += memcpy.o memset.o
+		ASSEMBLYARCH := 1
+	endif
+	ifneq (,$(findstring x86_64,$(ASSEMBLYARCH)))
+		OBJECTS += memcpy.o memmove.o memset.o
+		ASSEMBLYARCH := 2
+	endif
+endif
+
 ifeq ($(CONFIG_CXX_ALLOCATOR),true)
     # make sure LTO is compatible in case CC and CXX don't match (such as clang and g++)
     CXX := $(CC)
@@ -89,6 +120,10 @@ ifeq (,$(filter $(CONFIG_SELF_INIT),true false))
     $(error CONFIG_SELF_INIT must be true or false)
 endif
 
+ifeq (,$(filter $(CONFIG_BLOCK_OPS_CHECK_SIZE),true false))
+    $(error CONFIG_BLOCK_OPS_CHECK_SIZE must be true or false)
+endif
+
 CPPFLAGS += \
     -DCONFIG_SEAL_METADATA=$(CONFIG_SEAL_METADATA) \
     -DZERO_ON_FREE=$(CONFIG_ZERO_ON_FREE) \
@@ -108,7 +143,9 @@ CPPFLAGS += \
     -DCONFIG_CLASS_REGION_SIZE=$(CONFIG_CLASS_REGION_SIZE) \
     -DN_ARENA=$(CONFIG_N_ARENA) \
     -DCONFIG_STATS=$(CONFIG_STATS) \
-    -DCONFIG_SELF_INIT=$(CONFIG_SELF_INIT)
+    -DCONFIG_SELF_INIT=$(CONFIG_SELF_INIT) \
+    -DCONFIG_BLOCK_OPS_CHECK_SIZE=$(CONFIG_BLOCK_OPS_CHECK_SIZE) \
+    -DASSEMBLYARCH=$(ASSEMBLYARCH)
 
 $(OUT)/libhardened_malloc$(SUFFIX).so: $(OBJECTS) | $(OUT)
 	$(CC) $(CFLAGS) $(LDFLAGS) -shared $^ $(LDLIBS) -o $@
@@ -130,6 +167,12 @@ $(OUT)/random.o: random.c random.h chacha.h util.h $(CONFIG_FILE) | $(OUT)
 	$(COMPILE.c) $(OUTPUT_OPTION) $<
 $(OUT)/util.o: util.c util.h $(CONFIG_FILE) | $(OUT)
 	$(COMPILE.c) $(OUTPUT_OPTION) $<
+$(OUT)/memcpy.o: third_party/musl/x86_64/memcpy.S
+	$(COMPILE.S) $(OUTPUT_OPTION) $<
+$(OUT)/memmove.o: third_party/musl/x86_64/memmove.S
+	$(COMPILE.S) $(OUTPUT_OPTION) $<
+$(OUT)/memset.o: third_party/musl/x86_64/memset.S
+	$(COMPILE.S) $(OUTPUT_OPTION) $<
 
 check: tidy
 
diff --git a/README.md b/README.md
index 6a1a91b..972b6dd 100644
--- a/README.md
+++ b/README.md
@@ -276,6 +276,9 @@ The following boolean configuration options are available:
   hardware, which may become drastically lower in the future. Whether or not
   this feature is enabled, the metadata is all contained within an isolated
   memory region with high entropy random guard regions around it.
+* `CONFIG_BLOCK_OPS_CHECK_SIZE`: `true` or `false` (default) to ensure length
+  parameter of the memcpy/memmove/memset block operations and their wide
+  variants are within approximate bounds to minimize buffer overflows.
 
 The following integer configuration options are available:
 
diff --git a/config/default.mk b/config/default.mk
index 71b1cc4..b139c43 100644
--- a/config/default.mk
+++ b/config/default.mk
@@ -21,3 +21,4 @@ CONFIG_CLASS_REGION_SIZE := 34359738368 # 32GiB
 CONFIG_N_ARENA := 4
 CONFIG_STATS := false
 CONFIG_SELF_INIT := true
+CONFIG_BLOCK_OPS_CHECK_SIZE := false
diff --git a/config/light.mk b/config/light.mk
index 88a0e1f..7edd423 100644
--- a/config/light.mk
+++ b/config/light.mk
@@ -21,3 +21,4 @@ CONFIG_CLASS_REGION_SIZE := 34359738368 # 32GiB
 CONFIG_N_ARENA := 4
 CONFIG_STATS := false
 CONFIG_SELF_INIT := true
+CONFIG_BLOCK_OPS_CHECK_SIZE := false
diff --git a/h_malloc.c b/h_malloc.c
index 6221d0b..664bb37 100644
--- a/h_malloc.c
+++ b/h_malloc.c
@@ -528,7 +528,7 @@ static void set_canary(UNUSED const struct slab_metadata *metadata, UNUSED void
     }
 #endif
 
-    memcpy((char *)p + size - canary_size, &metadata->canary_value, canary_size);
+    h_memcpy_internal((char *)p + size - canary_size, &metadata->canary_value, canary_size);
 #endif
 }
 
@@ -541,7 +541,7 @@ static void check_canary(UNUSED const struct slab_metadata *metadata, UNUSED con
 #endif
 
     u64 canary_value;
-    memcpy(&canary_value, (const char *)p + size - canary_size, canary_size);
+    h_memcpy_internal(&canary_value, (const char *)p + size - canary_size, canary_size);
 
 #ifdef HAS_ARM_MTE
     if (unlikely(canary_value == 0)) {
@@ -831,7 +831,7 @@ static inline void deallocate_small(void *p, const size_t *expected_size) {
 #endif
 
         if (ZERO_ON_FREE && !skip_zero) {
-            memset(p, 0, size - canary_size);
+            h_memset_internal(p, 0, size - canary_size);
         }
     }
 
@@ -1502,7 +1502,7 @@ EXPORT void *h_calloc(size_t nmemb, size_t size) {
     total_size = adjust_size_for_canary(total_size);
     void *p = alloc(total_size);
     if (!ZERO_ON_FREE && likely(p != NULL) && total_size && total_size <= max_slab_size_class) {
-        memset(p, 0, total_size - canary_size);
+        h_memset_internal(p, 0, total_size - canary_size);
     }
 #ifdef HAS_ARM_MTE
     // use an assert instead of adding a conditional to memset() above (freed memory is always
@@ -1624,7 +1624,7 @@ EXPORT void *h_realloc(void *old, size_t size) {
                 mutex_unlock(&ra->lock);
 
                 if (memory_remap_fixed(old, old_size, new, size)) {
-                    memcpy(new, old, copy_size);
+                    h_memcpy_internal(new, old, copy_size);
                     deallocate_pages(old, old_size, old_guard_size);
                 } else {
                     memory_unmap((char *)old - old_guard_size, old_guard_size);
@@ -1646,7 +1646,7 @@ EXPORT void *h_realloc(void *old, size_t size) {
     if (copy_size > 0 && copy_size <= max_slab_size_class) {
         copy_size -= canary_size;
     }
-    memcpy(new, old_orig, copy_size);
+    h_memcpy_internal(new, old_orig, copy_size);
     if (old_size <= max_slab_size_class) {
         deallocate_small(old, NULL);
     } else {
@@ -1874,6 +1874,150 @@ EXPORT size_t h_malloc_object_size_fast(const void *p) {
     return SIZE_MAX;
 }
 
+#if CONFIG_BLOCK_OPS_CHECK_SIZE && !defined(HAS_ARM_MTE)
+#if ASSEMBLYARCH == 0
+inline void EXCLUDE_REPLACEMENT *memcpy_musl(void *restrict dst, const void *restrict src, size_t len) {
+    unsigned char *d = dst;
+    const unsigned char *s = src;
+
+    for (; len; len--) *d++ = *s++;
+
+    return dst;
+}
+#endif
+
+EXPORT void *h_memcpy_wrapped(void *restrict dst, const void *restrict src, size_t len) {
+    if(dst == src || len == 0) {
+        return dst;
+    }
+    if (dst < src + len && dst + len > src) {
+        fatal_error("memcpy overlap");
+    }
+    if (len > malloc_object_size(src)) {
+        fatal_error("memcpy read overflow");
+    }
+    if (len > malloc_object_size(dst)) {
+        fatal_error("memcpy buffer overflow");
+    }
+    return memcpy_musl(dst, src, len);
+}
+
+#if ASSEMBLYARCH == 0 || ASSEMBLYARCH == 1
+inline void EXCLUDE_REPLACEMENT *memmove_musl(void *dst, const void *src, size_t len) {
+    char *d = dst;
+    const char *s = src;
+
+    if (d < s) {
+        for (; len; len--) *d++ = *s++;
+    } else {
+        while (len) len--, d[len] = s[len];
+    }
+
+    return dst;
+}
+#endif
+
+EXPORT void *h_memmove_wrapped(void *dst, const void *src, size_t len) {
+    if(dst == src || len == 0) {
+        return dst;
+    }
+    if (len > malloc_object_size(src)) {
+        fatal_error("memmove read overflow");
+    }
+    if (len > malloc_object_size(dst)) {
+        fatal_error("memmove buffer overflow");
+    }
+    return memmove_musl(dst, src, len);
+}
+
+#if ASSEMBLYARCH == 0
+inline void EXCLUDE_REPLACEMENT *memset_musl(void *dst, int value, size_t len) {
+    unsigned char *s = dst;
+
+    for (; len; len--, s++) *s = value;
+
+    return dst;
+}
+#endif
+
+EXPORT void *h_memset_wrapped(void *dst, int value, size_t len) {
+    if(len == 0) {
+        return dst;
+    }
+    if (len > malloc_object_size(dst)) {
+        fatal_error("memset buffer overflow");
+    }
+    return memset_musl(dst, value, len);
+}
+
+inline wchar_t EXCLUDE_REPLACEMENT *wmemcpy_musl(wchar_t *restrict dst, const wchar_t *restrict src, size_t len) {
+    wchar_t *ret = dst;
+
+    while (len--) *dst++ = *src++;
+
+    return ret;
+}
+
+EXPORT wchar_t *h_wmemcpy_wrapped(wchar_t *restrict dst, const wchar_t *restrict src, size_t len) {
+    if(dst == src || len == 0) {
+        return dst;
+    }
+    if (dst < src + len && dst + len > src) {
+        fatal_error("wmemcpy overlap");
+    }
+    if (len > malloc_object_size(src)) {
+        fatal_error("wmemcpy read overflow");
+    }
+    if (len > malloc_object_size(dst)) {
+        fatal_error("wmemcpy buffer overflow");
+    }
+    return wmemcpy_musl(dst, src, len);
+}
+
+inline wchar_t EXCLUDE_REPLACEMENT *wmemmove_musl(wchar_t *dst, const wchar_t *src, size_t len) {
+    wchar_t *ret = dst;
+
+    if ((uintptr_t)dst-(uintptr_t)src < len * sizeof *dst) {
+        while (len--) dst[len] = src[len];
+    } else {
+	while (len--) *dst++ = *src++;
+    }
+
+    return ret;
+}
+
+EXPORT wchar_t *h_wmemmove_wrapped(wchar_t *dst, const wchar_t *src, size_t len) {
+    if(dst == src || len == 0) {
+        return dst;
+    }
+    if (len > malloc_object_size(src)) {
+        fatal_error("wmemmove read overflow");
+    }
+    if (len > malloc_object_size(dst)) {
+        fatal_error("wmemmove buffer overflow");
+    }
+    return wmemmove_musl(dst, src, len);
+}
+
+inline wchar_t EXCLUDE_REPLACEMENT *wmemset_musl(wchar_t *dst, wchar_t value, size_t len) {
+    wchar_t *ret = dst;
+
+    while (len--) *dst++ = value;
+
+    return ret;
+}
+
+EXPORT wchar_t *h_wmemset_wrapped(wchar_t *dst, wchar_t value, size_t len) {
+    if(len == 0) {
+        return dst;
+    }
+    if (len > malloc_object_size(dst)) {
+        fatal_error("wmemset buffer overflow");
+    }
+    return wmemset_musl(dst, value, len);
+}
+#endif
+
 EXPORT int h_mallopt(UNUSED int param, UNUSED int value) {
 #ifdef __ANDROID__
     if (param == M_PURGE) {
diff --git a/include/h_malloc.h b/include/h_malloc.h
index 0eee395..2691ba7 100644
--- a/include/h_malloc.h
+++ b/include/h_malloc.h
@@ -15,6 +15,14 @@ extern "C" {
 #define h_realloc realloc
 #define h_aligned_alloc aligned_alloc
 #define h_free free
+#if CONFIG_BLOCK_OPS_CHECK_SIZE && !defined(HAS_ARM_MTE)
+#define h_memcpy_wrapped memcpy
+#define h_memmove_wrapped memmove
+#define h_memset_wrapped memset
+#define h_wmemcpy_wrapped wmemcpy
+#define h_wmemmove_wrapped wmemmove
+#define h_wmemset_wrapped wmemset
+#endif
 
 #define h_posix_memalign posix_memalign
 
@@ -55,6 +63,41 @@ __attribute__((malloc)) __attribute__((alloc_size(2))) __attribute__((alloc_alig
 void *h_aligned_alloc(size_t alignment, size_t size);
 void h_free(void *ptr);
 
+#if CONFIG_BLOCK_OPS_CHECK_SIZE && !defined(HAS_ARM_MTE)
+#if defined(__clang__)
+#define EXCLUDE_REPLACEMENT __attribute__((optnone))
+#elif defined(__GNUC__) || defined(__GNUG__)
+#define EXCLUDE_REPLACEMENT __attribute__((__optimize__("-fno-tree-loop-distribute-patterns")))
+#endif
+#if ASSEMBLYARCH == 1 || ASSEMBLYARCH == 2
+extern void *memcpy_musl(void *dst, const void *src, size_t len);
+extern void *memset_musl(void *dst, int value, size_t len);
+#if ASSEMBLYARCH == 2
+extern void *memmove_musl(void *dst, const void *src, size_t len);
+#endif
+#else
+void *memcpy_musl(void *dst, const void *src, size_t len);
+void *memmove_musl(void *dst, const void *src, size_t len);
+void *memset_musl(void *dst, int value, size_t len);
+#endif
+void *h_memcpy_wrapped(void *dst, const void *src, size_t len);
+void *h_memmove_wrapped(void *dst, const void *src, size_t len);
+void *h_memset_wrapped(void *dst, int value, size_t len);
+wchar_t *wmemcpy_musl(wchar_t *dst, const wchar_t *src, size_t len);
+wchar_t *h_wmemcpy_wrapped(wchar_t *dst, const wchar_t *src, size_t len);
+wchar_t *wmemmove_musl(wchar_t *dst, const wchar_t *src, size_t len);
+wchar_t *h_wmemmove_wrapped(wchar_t *dst, const wchar_t *src, size_t len);
+wchar_t *wmemset_musl(wchar_t *dst, wchar_t value, size_t len);
+wchar_t *h_wmemset_wrapped(wchar_t *dst, wchar_t value, size_t len);
+#define h_memcpy_internal memcpy_musl
+#define h_memove_internal memmove_musl
+#define h_memset_internal memset_musl
+#else
+#define h_memcpy_internal __builtin_memcpy
+#define h_memove_internal __builtin_memmove
+#define h_memset_internal __builtin_memset
+#endif
+
 // POSIX
 int h_posix_memalign(void **memptr, size_t alignment, size_t size);
 
diff --git a/test/.gitignore b/test/.gitignore
index d37a6a7..fa4fa1e 100644
--- a/test/.gitignore
+++ b/test/.gitignore
@@ -41,4 +41,15 @@ overflow_small_8_byte
 uninitialized_read_large
 uninitialized_read_small
 realloc_init
+memcpy_buffer_overflow
+memcpy_read_overflow
+memcpy_valid_same
+memcpy_valid_mismatched
+memmove_buffer_overflow
+memmove_read_overflow
+memmove_valid_same
+memmove_valid_mismatched
+memset_buffer_overflow
+memset_valid_same
+memset_valid_mismatched
 __pycache__/
diff --git a/test/Makefile b/test/Makefile
index 0eb3921..cd9e664 100644
--- a/test/Makefile
+++ b/test/Makefile
@@ -67,7 +67,18 @@ EXECUTABLES := \
     invalid_malloc_object_size_small \
     invalid_malloc_object_size_small_quarantine \
     impossibly_large_malloc \
-    realloc_init
+    realloc_init \
+    memcpy_buffer_overflow \
+    memcpy_read_overflow \
+    memcpy_valid_same \
+    memcpy_valid_mismatched \
+    memmove_buffer_overflow \
+    memmove_read_overflow \
+    memmove_valid_same \
+    memmove_valid_mismatched \
+    memset_buffer_overflow \
+    memset_valid_same \
+    memset_valid_mismatched
 
 all: $(EXECUTABLES)
 
diff --git a/test/memcpy_buffer_overflow.c b/test/memcpy_buffer_overflow.c
new file mode 100644
index 0000000..16cab77
--- /dev/null
+++ b/test/memcpy_buffer_overflow.c
@@ -0,0 +1,15 @@
+#include <stdlib.h>
+#include <string.h>
+
+#include "test_util.h"
+
+OPTNONE int main(void) {
+    char *firstbuffer = malloc(16);
+    char *secondbuffer = malloc(32);
+    if (!firstbuffer && !secondbuffer) {
+        return 1;
+    }
+    memset(secondbuffer, 'a', 32);
+    memcpy(firstbuffer, secondbuffer, 32);
+    return 1;
+}
diff --git a/test/memcpy_read_overflow.c b/test/memcpy_read_overflow.c
new file mode 100644
index 0000000..cf51498
--- /dev/null
+++ b/test/memcpy_read_overflow.c
@@ -0,0 +1,15 @@
+#include <stdlib.h>
+#include <string.h>
+
+#include "test_util.h"
+
+OPTNONE int main(void) {
+    char *firstbuffer = malloc(32);
+    char *secondbuffer = malloc(16);
+    if (!firstbuffer && !secondbuffer) {
+        return 1;
+    }
+    memset(secondbuffer, 'a', 16);
+    memcpy(firstbuffer, secondbuffer, 32);
+    return 1;
+}
diff --git a/test/memcpy_valid_mismatched.c b/test/memcpy_valid_mismatched.c
new file mode 100644
index 0000000..81d718e
--- /dev/null
+++ b/test/memcpy_valid_mismatched.c
@@ -0,0 +1,15 @@
+#include <stdlib.h>
+#include <string.h>
+
+#include "test_util.h"
+
+OPTNONE int main(void) {
+    char *firstbuffer = malloc(32);
+    char *secondbuffer = malloc(16);
+    if (!firstbuffer && !secondbuffer) {
+        return 1;
+    }
+    memset(secondbuffer, 'a', 16);
+    memcpy(firstbuffer, secondbuffer, 16);
+    return 0;
+}
diff --git a/test/memcpy_valid_same.c b/test/memcpy_valid_same.c
new file mode 100644
index 0000000..1b408f0
--- /dev/null
+++ b/test/memcpy_valid_same.c
@@ -0,0 +1,15 @@
+#include <stdlib.h>
+#include <string.h>
+
+#include "test_util.h"
+
+OPTNONE int main(void) {
+    char *firstbuffer = malloc(16);
+    char *secondbuffer = malloc(16);
+    if (!firstbuffer && !secondbuffer) {
+        return 1;
+    }
+    memset(secondbuffer, 'a', 16);
+    memcpy(firstbuffer, secondbuffer, 16);
+    return 0;
+}
diff --git a/test/memmove_buffer_overflow.c b/test/memmove_buffer_overflow.c
new file mode 100644
index 0000000..c83bf97
--- /dev/null
+++ b/test/memmove_buffer_overflow.c
@@ -0,0 +1,15 @@
+#include <stdlib.h>
+#include <string.h>
+
+#include "test_util.h"
+
+OPTNONE int main(void) {
+    char *firstbuffer = malloc(16);
+    char *secondbuffer = malloc(32);
+    if (!firstbuffer && !secondbuffer) {
+        return 1;
+    }
+    memset(secondbuffer, 'a', 32);
+    memmove(firstbuffer, secondbuffer, 32);
+    return 1;
+}
diff --git a/test/memmove_read_overflow.c b/test/memmove_read_overflow.c
new file mode 100644
index 0000000..73e4509
--- /dev/null
+++ b/test/memmove_read_overflow.c
@@ -0,0 +1,15 @@
+#include <stdlib.h>
+#include <string.h>
+
+#include "test_util.h"
+
+OPTNONE int main(void) {
+    char *firstbuffer = malloc(32);
+    char *secondbuffer = malloc(16);
+    if (!firstbuffer && !secondbuffer) {
+        return 1;
+    }
+    memset(secondbuffer, 'a', 16);
+    memmove(firstbuffer, secondbuffer, 32);
+    return 1;
+}
diff --git a/test/memmove_valid_mismatched.c b/test/memmove_valid_mismatched.c
new file mode 100644
index 0000000..5dd1bde
--- /dev/null
+++ b/test/memmove_valid_mismatched.c
@@ -0,0 +1,15 @@
+#include <stdlib.h>
+#include <string.h>
+
+#include "test_util.h"
+
+OPTNONE int main(void) {
+    char *firstbuffer = malloc(32);
+    char *secondbuffer = malloc(16);
+    if (!firstbuffer && !secondbuffer) {
+        return 1;
+    }
+    memset(secondbuffer, 'a', 16);
+    memmove(firstbuffer, secondbuffer, 16);
+    return 0;
+}
diff --git a/test/memmove_valid_same.c b/test/memmove_valid_same.c
new file mode 100644
index 0000000..2593abc
--- /dev/null
+++ b/test/memmove_valid_same.c
@@ -0,0 +1,15 @@
+#include <stdlib.h>
+#include <string.h>
+
+#include "test_util.h"
+
+OPTNONE int main(void) {
+    char *firstbuffer = malloc(16);
+    char *secondbuffer = malloc(16);
+    if (!firstbuffer && !secondbuffer) {
+        return 1;
+    }
+    memset(secondbuffer, 'a', 16);
+    memmove(firstbuffer, secondbuffer, 16);
+    return 0;
+}
diff --git a/test/memset_buffer_overflow.c b/test/memset_buffer_overflow.c
new file mode 100644
index 0000000..8f9e989
--- /dev/null
+++ b/test/memset_buffer_overflow.c
@@ -0,0 +1,13 @@
+#include <stdlib.h>
+#include <string.h>
+
+#include "test_util.h"
+
+OPTNONE int main(void) {
+    char *buffer = malloc(16);
+    if (!buffer) {
+        return 1;
+    }
+    memset(buffer, 'a', 32);
+    return 1;
+}
diff --git a/test/memset_valid_mismatched.c b/test/memset_valid_mismatched.c
new file mode 100644
index 0000000..f57fef6
--- /dev/null
+++ b/test/memset_valid_mismatched.c
@@ -0,0 +1,13 @@
+#include <stdlib.h>
+#include <string.h>
+
+#include "test_util.h"
+
+OPTNONE int main(void) {
+    char *buffer = malloc(32);
+    if (!buffer) {
+        return 1;
+    }
+    memset(buffer, 'a', 16);
+    return 0;
+}
diff --git a/test/memset_valid_same.c b/test/memset_valid_same.c
new file mode 100644
index 0000000..824c18f
--- /dev/null
+++ b/test/memset_valid_same.c
@@ -0,0 +1,13 @@
+#include <stdlib.h>
+#include <string.h>
+
+#include "test_util.h"
+
+OPTNONE int main(void) {
+    char *buffer = malloc(16);
+    if (!buffer) {
+        return 1;
+    }
+    memset(buffer, 'a', 16);
+    return 0;
+}
diff --git a/test/test_smc.py b/test/test_smc.py
index 170278e..88bb4e3 100644
--- a/test/test_smc.py
+++ b/test/test_smc.py
@@ -238,5 +238,70 @@ class TestSimpleMemoryCorruption(unittest.TestCase):
             "realloc_init")
         self.assertEqual(returncode, 0)
 
+    #def test_memcpy_buffer_overflow(self):
+    #    _stdout, stderr, returncode = self.run_test(
+    #        "memcpy_buffer_overflow")
+    #    self.assertEqual(returncode, -6)
+    #    self.assertEqual(stderr.decode(
+    #        "utf-8"), "fatal allocator error: memcpy buffer overflow\n")
+
+    #def test_memcpy_read_overflow(self):
+    #    _stdout, stderr, returncode = self.run_test(
+    #        "memcpy_read_overflow")
+    #    self.assertEqual(returncode, -6)
+    #    self.assertEqual(stderr.decode(
+    #        "utf-8"), "fatal allocator error: memcpy read overflow\n")
+
+    def test_memcpy_valid_same(self):
+        _stdout, _stderr, returncode = self.run_test(
+            "memcpy_valid_same")
+        self.assertEqual(returncode, 0)
+
+    def test_memcpy_valid_mismatched(self):
+        _stdout, _stderr, returncode = self.run_test(
+            "memcpy_valid_mismatched")
+        self.assertEqual(returncode, 0)
+
+    #def test_memmove_buffer_overflow(self):
+    #    _stdout, stderr, returncode = self.run_test(
+    #        "memmove_buffer_overflow")
+    #    self.assertEqual(returncode, -6)
+    #    self.assertEqual(stderr.decode(
+    #        "utf-8"), "fatal allocator error: memmove buffer overflow\n")
+
+    #def test_memmove_read_overflow(self):
+    #    _stdout, stderr, returncode = self.run_test(
+    #        "memmove_read_overflow")
+    #    self.assertEqual(returncode, -6)
+    #    self.assertEqual(stderr.decode(
+    #        "utf-8"), "fatal allocator error: memmove read overflow\n")
+
+    def test_memmove_valid_same(self):
+        _stdout, _stderr, returncode = self.run_test(
+            "memmove_valid_same")
+        self.assertEqual(returncode, 0)
+
+    def test_memmove_valid_mismatched(self):
+        _stdout, _stderr, returncode = self.run_test(
+            "memmove_valid_mismatched")
+        self.assertEqual(returncode, 0)
+
+    #def test_memset_buffer_overflow(self):
+    #    _stdout, stderr, returncode = self.run_test(
+    #        "memset_buffer_overflow")
+    #    self.assertEqual(returncode, -6)
+    #    self.assertEqual(stderr.decode(
+    #        "utf-8"), "fatal allocator error: memset buffer overflow\n")
+
+    def test_memset_valid_same(self):
+        _stdout, _stderr, returncode = self.run_test(
+            "memset_valid_same")
+        self.assertEqual(returncode, 0)
+
+    def test_memset_valid_mismatched(self):
+        _stdout, _stderr, returncode = self.run_test(
+            "memset_valid_mismatched")
+        self.assertEqual(returncode, 0)
+
 if __name__ == '__main__':
     unittest.main()
diff --git a/third_party/musl/aarch64/memcpy.S b/third_party/musl/aarch64/memcpy.S
new file mode 100644
index 0000000..37c4602
--- /dev/null
+++ b/third_party/musl/aarch64/memcpy.S
@@ -0,0 +1,186 @@
+/*
+ * memcpy - copy memory area
+ *
+ * Copyright (c) 2012-2020, Arm Limited.
+ * SPDX-License-Identifier: MIT
+ */
+
+/* Assumptions:
+ *
+ * ARMv8-a, AArch64, unaligned accesses.
+ *
+ */
+
+#define dstin   x0
+#define src     x1
+#define count   x2
+#define dst     x3
+#define srcend  x4
+#define dstend  x5
+#define A_l     x6
+#define A_lw    w6
+#define A_h     x7
+#define B_l     x8
+#define B_lw    w8
+#define B_h     x9
+#define C_l     x10
+#define C_lw    w10
+#define C_h     x11
+#define D_l     x12
+#define D_h     x13
+#define E_l     x14
+#define E_h     x15
+#define F_l     x16
+#define F_h     x17
+#define G_l     count
+#define G_h     dst
+#define H_l     src
+#define H_h     srcend
+#define tmp1    x14
+
+/* This implementation of memcpy uses unaligned accesses and branchless
+   sequences to keep the code small, simple and improve performance.
+
+   Copies are split into 3 main cases: small copies of up to 32 bytes, medium
+   copies of up to 128 bytes, and large copies.  The overhead of the overlap
+   check is negligible since it is only required for large copies.
+
+   Large copies use a software pipelined loop processing 64 bytes per iteration.
+   The destination pointer is 16-byte aligned to minimize unaligned accesses.
+   The loop tail is handled by always copying 64 bytes from the end.
+*/
+
+.global memcpy_musl
+.type memcpy_musl,%function
+memcpy_musl:
+	add     srcend, src, count
+	add     dstend, dstin, count
+	cmp     count, 128
+	b.hi    .Lcopy_long
+	cmp     count, 32
+	b.hi    .Lcopy32_128
+
+	/* Small copies: 0..32 bytes.  */
+	cmp     count, 16
+	b.lo    .Lcopy16
+	ldp     A_l, A_h, [src]
+	ldp     D_l, D_h, [srcend, -16]
+	stp     A_l, A_h, [dstin]
+	stp     D_l, D_h, [dstend, -16]
+	ret
+
+	/* Copy 8-15 bytes.  */
+.Lcopy16:
+	tbz     count, 3, .Lcopy8
+	ldr     A_l, [src]
+	ldr     A_h, [srcend, -8]
+	str     A_l, [dstin]
+	str     A_h, [dstend, -8]
+	ret
+
+	.p2align 3
+	/* Copy 4-7 bytes.  */
+.Lcopy8:
+	tbz     count, 2, .Lcopy4
+	ldr     A_lw, [src]
+	ldr     B_lw, [srcend, -4]
+	str     A_lw, [dstin]
+	str     B_lw, [dstend, -4]
+	ret
+
+	/* Copy 0..3 bytes using a branchless sequence.  */
+.Lcopy4:
+	cbz     count, .Lcopy0
+	lsr     tmp1, count, 1
+	ldrb    A_lw, [src]
+	ldrb    C_lw, [srcend, -1]
+	ldrb    B_lw, [src, tmp1]
+	strb    A_lw, [dstin]
+	strb    B_lw, [dstin, tmp1]
+	strb    C_lw, [dstend, -1]
+.Lcopy0:
+	ret
+
+	.p2align 4
+	/* Medium copies: 33..128 bytes.  */
+.Lcopy32_128:
+	ldp     A_l, A_h, [src]
+	ldp     B_l, B_h, [src, 16]
+	ldp     C_l, C_h, [srcend, -32]
+	ldp     D_l, D_h, [srcend, -16]
+	cmp     count, 64
+	b.hi    .Lcopy128
+	stp     A_l, A_h, [dstin]
+	stp     B_l, B_h, [dstin, 16]
+	stp     C_l, C_h, [dstend, -32]
+	stp     D_l, D_h, [dstend, -16]
+	ret
+
+	.p2align 4
+	/* Copy 65..128 bytes.  */
+.Lcopy128:
+	ldp     E_l, E_h, [src, 32]
+	ldp     F_l, F_h, [src, 48]
+	cmp     count, 96
+	b.ls    .Lcopy96
+	ldp     G_l, G_h, [srcend, -64]
+	ldp     H_l, H_h, [srcend, -48]
+	stp     G_l, G_h, [dstend, -64]
+	stp     H_l, H_h, [dstend, -48]
+.Lcopy96:
+	stp     A_l, A_h, [dstin]
+	stp     B_l, B_h, [dstin, 16]
+	stp     E_l, E_h, [dstin, 32]
+	stp     F_l, F_h, [dstin, 48]
+	stp     C_l, C_h, [dstend, -32]
+	stp     D_l, D_h, [dstend, -16]
+	ret
+
+	.p2align 4
+	/* Copy more than 128 bytes.  */
+.Lcopy_long:
+
+	/* Copy 16 bytes and then align dst to 16-byte alignment.  */
+
+	ldp     D_l, D_h, [src]
+	and     tmp1, dstin, 15
+	bic     dst, dstin, 15
+	sub     src, src, tmp1
+	add     count, count, tmp1      /* Count is now 16 too large.  */
+	ldp     A_l, A_h, [src, 16]
+	stp     D_l, D_h, [dstin]
+	ldp     B_l, B_h, [src, 32]
+	ldp     C_l, C_h, [src, 48]
+	ldp     D_l, D_h, [src, 64]!
+	subs    count, count, 128 + 16  /* Test and readjust count.  */
+	b.ls    .Lcopy64_from_end
+
+.Lloop64:
+	stp     A_l, A_h, [dst, 16]
+	ldp     A_l, A_h, [src, 16]
+	stp     B_l, B_h, [dst, 32]
+	ldp     B_l, B_h, [src, 32]
+	stp     C_l, C_h, [dst, 48]
+	ldp     C_l, C_h, [src, 48]
+	stp     D_l, D_h, [dst, 64]!
+	ldp     D_l, D_h, [src, 64]!
+	subs    count, count, 64
+	b.hi    .Lloop64
+
+	/* Write the last iteration and copy 64 bytes from the end.  */
+.Lcopy64_from_end:
+	ldp     E_l, E_h, [srcend, -64]
+	stp     A_l, A_h, [dst, 16]
+	ldp     A_l, A_h, [srcend, -48]
+	stp     B_l, B_h, [dst, 32]
+	ldp     B_l, B_h, [srcend, -32]
+	stp     C_l, C_h, [dst, 48]
+	ldp     C_l, C_h, [srcend, -16]
+	stp     D_l, D_h, [dst, 64]
+	stp     E_l, E_h, [dstend, -64]
+	stp     A_l, A_h, [dstend, -48]
+	stp     B_l, B_h, [dstend, -32]
+	stp     C_l, C_h, [dstend, -16]
+	ret
+
+.size memcpy_musl,.-memcpy_musl
diff --git a/third_party/musl/aarch64/memset.S b/third_party/musl/aarch64/memset.S
new file mode 100644
index 0000000..9c82937
--- /dev/null
+++ b/third_party/musl/aarch64/memset.S
@@ -0,0 +1,115 @@
+/*
+ * memset - fill memory with a constant byte
+ *
+ * Copyright (c) 2012-2020, Arm Limited.
+ * SPDX-License-Identifier: MIT
+ */
+
+/* Assumptions:
+ *
+ * ARMv8-a, AArch64, Advanced SIMD, unaligned accesses.
+ *
+ */
+
+#define dstin   x0
+#define val     x1
+#define valw    w1
+#define count   x2
+#define dst     x3
+#define dstend  x4
+#define zva_val x5
+
+.global memset_musl
+.type memset_musl,%function
+memset_musl:
+
+	dup     v0.16B, valw
+	add     dstend, dstin, count
+
+	cmp     count, 96
+	b.hi    .Lset_long
+	cmp     count, 16
+	b.hs    .Lset_medium
+	mov     val, v0.D[0]
+
+	/* Set 0..15 bytes.  */
+	tbz     count, 3, 1f
+	str     val, [dstin]
+	str     val, [dstend, -8]
+	ret
+	nop
+1:      tbz     count, 2, 2f
+	str     valw, [dstin]
+	str     valw, [dstend, -4]
+	ret
+2:      cbz     count, 3f
+	strb    valw, [dstin]
+	tbz     count, 1, 3f
+	strh    valw, [dstend, -2]
+3:      ret
+
+	/* Set 17..96 bytes.  */
+.Lset_medium:
+	str     q0, [dstin]
+	tbnz    count, 6, .Lset96
+	str     q0, [dstend, -16]
+	tbz     count, 5, 1f
+	str     q0, [dstin, 16]
+	str     q0, [dstend, -32]
+1:      ret
+
+	.p2align 4
+	/* Set 64..96 bytes.  Write 64 bytes from the start and
+	   32 bytes from the end.  */
+.Lset96:
+	str     q0, [dstin, 16]
+	stp     q0, q0, [dstin, 32]
+	stp     q0, q0, [dstend, -32]
+	ret
+
+	.p2align 4
+.Lset_long:
+	and     valw, valw, 255
+	bic     dst, dstin, 15
+	str     q0, [dstin]
+	cmp     count, 160
+	ccmp    valw, 0, 0, hs
+	b.ne    .Lno_zva
+
+#ifndef SKIP_ZVA_CHECK
+	mrs     zva_val, dczid_el0
+	and     zva_val, zva_val, 31
+	cmp     zva_val, 4              /* ZVA size is 64 bytes.  */
+	b.ne    .Lno_zva
+#endif
+	str     q0, [dst, 16]
+	stp     q0, q0, [dst, 32]
+	bic     dst, dst, 63
+	sub     count, dstend, dst      /* Count is now 64 too large.  */
+	sub     count, count, 128       /* Adjust count and bias for loop.  */
+
+	.p2align 4
+.Lzva_loop:
+	add     dst, dst, 64
+	dc      zva, dst
+	subs    count, count, 64
+	b.hi    .Lzva_loop
+	stp     q0, q0, [dstend, -64]
+	stp     q0, q0, [dstend, -32]
+	ret
+
+.Lno_zva:
+	sub     count, dstend, dst      /* Count is 16 too large.  */
+	sub     dst, dst, 16            /* Dst is biased by -32.  */
+	sub     count, count, 64 + 16   /* Adjust count and bias for loop.  */
+.Lno_zva_loop:
+	stp     q0, q0, [dst, 32]
+	stp     q0, q0, [dst, 64]!
+	subs    count, count, 64
+	b.hi    .Lno_zva_loop
+	stp     q0, q0, [dstend, -64]
+	stp     q0, q0, [dstend, -32]
+	ret
+
+.size memset_musl,.-memset_musl
+
diff --git a/third_party/musl/x86_64/memcpy.S b/third_party/musl/x86_64/memcpy.S
new file mode 100644
index 0000000..cf72728
--- /dev/null
+++ b/third_party/musl/x86_64/memcpy.S
@@ -0,0 +1,25 @@
+.global memcpy_musl
+.global __memcpy_fwd_musl
+.hidden __memcpy_fwd_musl
+.type memcpy_musl,@function
+memcpy_musl:
+__memcpy_fwd_musl:
+	mov %rdi,%rax
+	cmp $8,%rdx
+	jc 1f
+	test $7,%edi
+	jz 1f
+2:	movsb
+	dec %rdx
+	test $7,%edi
+	jnz 2b
+1:	mov %rdx,%rcx
+	shr $3,%rcx
+	rep
+	movsq
+	and $7,%edx
+	jz 1f
+2:	movsb
+	dec %edx
+	jnz 2b
+1:	ret
diff --git a/third_party/musl/x86_64/memmove.S b/third_party/musl/x86_64/memmove.S
new file mode 100644
index 0000000..0b1b5a0
--- /dev/null
+++ b/third_party/musl/x86_64/memmove.S
@@ -0,0 +1,16 @@
+.global memmove_musl
+.type memmove_musl,@function
+memmove_musl:
+	mov %rdi,%rax
+	sub %rsi,%rax
+	cmp %rdx,%rax
+.hidden __memcpy_fwd_musl
+	jae __memcpy_fwd_musl
+	mov %rdx,%rcx
+	lea -1(%rdi,%rdx),%rdi
+	lea -1(%rsi,%rdx),%rsi
+	std
+	rep movsb
+	cld
+	lea 1(%rdi),%rax
+	ret
diff --git a/third_party/musl/x86_64/memset.S b/third_party/musl/x86_64/memset.S
new file mode 100644
index 0000000..64794f5
--- /dev/null
+++ b/third_party/musl/x86_64/memset.S
@@ -0,0 +1,72 @@
+.global memset_musl
+.type memset_musl,@function
+memset_musl:
+	movzbq %sil,%rax
+	mov $0x101010101010101,%r8
+	imul %r8,%rax
+
+	cmp $126,%rdx
+	ja 2f
+
+	test %edx,%edx
+	jz 1f
+
+	mov %sil,(%rdi)
+	mov %sil,-1(%rdi,%rdx)
+	cmp $2,%edx
+	jbe 1f
+
+	mov %ax,1(%rdi)
+	mov %ax,(-1-2)(%rdi,%rdx)
+	cmp $6,%edx
+	jbe 1f
+
+	mov %eax,(1+2)(%rdi)
+	mov %eax,(-1-2-4)(%rdi,%rdx)
+	cmp $14,%edx
+	jbe 1f
+
+	mov %rax,(1+2+4)(%rdi)
+	mov %rax,(-1-2-4-8)(%rdi,%rdx)
+	cmp $30,%edx
+	jbe 1f
+
+	mov %rax,(1+2+4+8)(%rdi)
+	mov %rax,(1+2+4+8+8)(%rdi)
+	mov %rax,(-1-2-4-8-16)(%rdi,%rdx)
+	mov %rax,(-1-2-4-8-8)(%rdi,%rdx)
+	cmp $62,%edx
+	jbe 1f
+
+	mov %rax,(1+2+4+8+16)(%rdi)
+	mov %rax,(1+2+4+8+16+8)(%rdi)
+	mov %rax,(1+2+4+8+16+16)(%rdi)
+	mov %rax,(1+2+4+8+16+24)(%rdi)
+	mov %rax,(-1-2-4-8-16-32)(%rdi,%rdx)
+	mov %rax,(-1-2-4-8-16-24)(%rdi,%rdx)
+	mov %rax,(-1-2-4-8-16-16)(%rdi,%rdx)
+	mov %rax,(-1-2-4-8-16-8)(%rdi,%rdx)
+
+1:	mov %rdi,%rax
+	ret
+
+2:	test $15,%edi
+	mov %rdi,%r8
+	mov %rax,-8(%rdi,%rdx)
+	mov %rdx,%rcx
+	jnz 2f
+
+1:	shr $3,%rcx
+	rep
+	stosq
+	mov %r8,%rax
+	ret
+
+2:	xor %edx,%edx
+	sub %edi,%edx
+	and $15,%edx
+	mov %rax,(%rdi)
+	mov %rax,8(%rdi)
+	sub %rdx,%rcx
+	add %rdx,%rdi
+	jmp 1b
